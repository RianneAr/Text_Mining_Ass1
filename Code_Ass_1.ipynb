{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc0e529c",
   "metadata": {},
   "source": [
    "# Code Assignment 1 Text Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b175aa15",
   "metadata": {},
   "source": [
    "The following code was used to perform the analyses from assignment one. First, nine different models were tested using the 20newsgroups data. Next, the best performing model was used to investigate different parameters for the CountVectorizer function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8065a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fdacb2e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#https://medium.com/all-things-ai/in-depth-parameter-tuning-for-svc-758215394769\n",
    "#https://towardsdatascience.com/random-forest-hyperparameters-and-how-to-fine-tune-them-17aee785ee0d#:~:text=The%20most%20important%20hyper%2Dparameters,MSE%20or%20MAE%20for%20regression)\n",
    "#https://medium.com/@siyao_sui/nlp-with-the-20-newsgroups-dataset-ab35cd0ea902\n",
    "#https://gist.github.com/SuyashLakhotia/f26d249d5cbb7a3784b64c20bea5a460\n",
    "#https://towardsdatascience.com/svm-hyperparameters-explained-with-visualizations-143e48cb701b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8a15b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train and test data\n",
    "twenty_train = fetch_20newsgroups(subset='train', shuffle=True, random_state=42)\n",
    "twenty_test = fetch_20newsgroups(subset='test', shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bb0e6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define 9 models\n",
    "RF = RandomForestClassifier()\n",
    "SV = SVC()\n",
    "\n",
    "text_clf1 = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "text_clf2 = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer(use_idf = False)),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "text_clf3 = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "text_clf4 = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', RF),\n",
    "])\n",
    "\n",
    "text_clf5 = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer(use_idf = False)),\n",
    "    ('clf', RF),\n",
    "])\n",
    "\n",
    "text_clf6 = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', RF),\n",
    "])\n",
    "\n",
    "text_clf7 = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SV),\n",
    "])\n",
    "text_clf8 = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer(use_idf = False)),\n",
    "    ('clf', SV),\n",
    "])\n",
    "\n",
    "text_clf9 = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', SV),\n",
    "])\n",
    "\n",
    "model_list = [text_clf1, text_clf2, text_clf3, text_clf4, text_clf5, text_clf6, text_clf7, text_clf8, text_clf9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e1e3110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
      "                ('clf', MultinomialNB())]) \n",
      "Accuracy:  0.7738980350504514 \n",
      "F1:  0.7557542971333199 \n",
      "Precision:  0.8255310124210137 \n",
      "Recall:  0.756525006352595 \n",
      "\n",
      "Model:  Pipeline(steps=[('vect', CountVectorizer()),\n",
      "                ('tfidf', TfidfTransformer(use_idf=False)),\n",
      "                ('clf', MultinomialNB())]) \n",
      "Accuracy:  0.7052575677110993 \n",
      "F1:  0.6727826639341477 \n",
      "Precision:  0.7924314057319584 \n",
      "Recall:  0.6821951093902918 \n",
      "\n",
      "Model:  Pipeline(steps=[('vect', CountVectorizer()), ('clf', MultinomialNB())]) \n",
      "Accuracy:  0.7728359001593202 \n",
      "F1:  0.745098233005215 \n",
      "Precision:  0.7621626411174734 \n",
      "Recall:  0.7636463041415988 \n",
      "\n",
      "Model:  Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
      "                ('clf', RandomForestClassifier())]) \n",
      "Accuracy:  0.7608868826340945 \n",
      "F1:  0.7474646528349933 \n",
      "Precision:  0.7736778511628659 \n",
      "Recall:  0.7491164438873836 \n",
      "\n",
      "Model:  Pipeline(steps=[('vect', CountVectorizer()),\n",
      "                ('tfidf', TfidfTransformer(use_idf=False)),\n",
      "                ('clf', RandomForestClassifier())]) \n",
      "Accuracy:  0.7562400424853957 \n",
      "F1:  0.7425080319972394 \n",
      "Precision:  0.7640345044906038 \n",
      "Recall:  0.7442690028669854 \n",
      "\n",
      "Model:  Pipeline(steps=[('vect', CountVectorizer()), ('clf', RandomForestClassifier())]) \n",
      "Accuracy:  0.7672596919808816 \n",
      "F1:  0.7546185009052507 \n",
      "Precision:  0.7795874437100503 \n",
      "Recall:  0.7554277188020658 \n",
      "\n",
      "Model:  Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
      "                ('clf', SVC())]) \n",
      "Accuracy:  0.8186404673393521 \n",
      "F1:  0.8135540041784731 \n",
      "Precision:  0.8274134771443714 \n",
      "Recall:  0.8102879624833934 \n",
      "\n",
      "Model:  Pipeline(steps=[('vect', CountVectorizer()),\n",
      "                ('tfidf', TfidfTransformer(use_idf=False)), ('clf', SVC())]) \n",
      "Accuracy:  0.7446893255443441 \n",
      "F1:  0.7367813243061698 \n",
      "Precision:  0.7495887500253671 \n",
      "Recall:  0.7350676620893993 \n",
      "\n",
      "Model:  Pipeline(steps=[('vect', CountVectorizer()), ('clf', SVC())]) \n",
      "Accuracy:  0.15108868826340946 \n",
      "F1:  0.1337679956659171 \n",
      "Precision:  0.4173628717422842 \n",
      "Recall:  0.1464091524800676 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate performance statistics for each model\n",
    "accuracy = []\n",
    "f1 = []\n",
    "precision = []\n",
    "recall = []\n",
    "\n",
    "for text_clf in model_list:\n",
    "    \n",
    "    text_clf.fit(twenty_train.data, twenty_train.target)\n",
    "    docs_test = twenty_test.data\n",
    "    predicted = text_clf.predict(docs_test)\n",
    "    \n",
    "    acc = np.mean(predicted == twenty_test.target)\n",
    "    prec = metrics.precision_score(twenty_test.target, predicted, average = 'macro', zero_division = 0)\n",
    "    rec = metrics.recall_score(twenty_test.target, predicted, average = 'macro', zero_division = 0)\n",
    "    f = metrics.f1_score(twenty_test.target, predicted, average = 'macro', zero_division = 0)\n",
    "    \n",
    "    accuracy.append(acc)\n",
    "    f1.append(f)\n",
    "    precision.append(prec)\n",
    "    recall.append(rec)\n",
    "    \n",
    "    print('Model: ', text_clf, \n",
    "          '\\nAccuracy: ', acc, \n",
    "          '\\nF1: ', f,\n",
    "          '\\nPrecision: ', prec,\n",
    "          '\\nRecall: ', rec, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4f58517",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  Pipeline(steps=[('vect',\n",
      "                 CountVectorizer(max_features=50000, stop_words='english')),\n",
      "                ('tfidf', TfidfTransformer()), ('clf', SVC())]) \n",
      "Accuracy:  0.8279341476367499 \n",
      "F1:  0.8228387487974638 \n",
      "Precision:  0.8368358840102996 \n",
      "Recall:  0.8192762842275634 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_clf_params = Pipeline([\n",
    "    ('vect', CountVectorizer(stop_words='english',max_features=50000)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SV),\n",
    "])\n",
    "\n",
    "text_clf_params.fit(twenty_train.data, twenty_train.target)\n",
    "docs_test = twenty_test.data\n",
    "predicted = text_clf_params.predict(docs_test)\n",
    "\n",
    "acc = np.mean(predicted == twenty_test.target)\n",
    "prec = metrics.precision_score(twenty_test.target, predicted, average = 'macro')\n",
    "rec = metrics.recall_score(twenty_test.target, predicted, average = 'macro')\n",
    "f = metrics.f1_score(twenty_test.target, predicted, average = 'macro')\n",
    "\n",
    "print('Model: ', text_clf_params,\n",
    "      '\\nAccuracy: ', acc,\n",
    "      '\\nF1: ', f,\n",
    "      '\\nPrecision: ', prec,\n",
    "      '\\nRecall: ', rec, '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
