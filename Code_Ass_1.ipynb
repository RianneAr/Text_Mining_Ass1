{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f8065a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8fdacb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://medium.com/all-things-ai/in-depth-parameter-tuning-for-svc-758215394769\n",
    "#https://towardsdatascience.com/random-forest-hyperparameters-and-how-to-fine-tune-them-17aee785ee0d#:~:text=The%20most%20important%20hyper%2Dparameters,MSE%20or%20MAE%20for%20regression)\n",
    "#https://medium.com/@siyao_sui/nlp-with-the-20-newsgroups-dataset-ab35cd0ea902\n",
    "#https://gist.github.com/SuyashLakhotia/f26d249d5cbb7a3784b64c20bea5a460\n",
    "#https://towardsdatascience.com/svm-hyperparameters-explained-with-visualizations-143e48cb701b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f8a15b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "twenty_train = fetch_20newsgroups(subset='train', shuffle=True, random_state=42)\n",
    "twenty_test = fetch_20newsgroups(subset='test', shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8bb0e6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = RandomForestClassifier()#n_estimators = 150, max_features = 'sqrt')\n",
    "SV = SVC()#C = 5, gamma = 0.75)\n",
    "\n",
    "text_clf1 = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "text_clf2 = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer(use_idf = False)),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "text_clf3 = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "text_clf4 = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', RF),\n",
    "])\n",
    "\n",
    "text_clf5 = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer(use_idf = False)),\n",
    "    ('clf', RF),\n",
    "])\n",
    "\n",
    "text_clf6 = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', RF),\n",
    "])\n",
    "\n",
    "text_clf7 = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SV),\n",
    "])\n",
    "text_clf8 = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer(use_idf = False)),\n",
    "    ('clf', SV),\n",
    "])\n",
    "\n",
    "text_clf9 = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', SV),\n",
    "])\n",
    "\n",
    "model_list = [text_clf1, text_clf2, text_clf3, text_clf4, text_clf5, text_clf6, text_clf7, text_clf8, text_clf9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1e3110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
      "                ('clf', MultinomialNB())]) \n",
      "Accuracy:  0.7738980350504514 \n",
      "F1:  0.7557542971333199 \n",
      "Precision:  0.8255310124210137 \n",
      "Recall:  0.756525006352595 \n",
      "\n",
      "Model:  Pipeline(steps=[('vect', CountVectorizer()),\n",
      "                ('tfidf', TfidfTransformer(use_idf=False)),\n",
      "                ('clf', MultinomialNB())]) \n",
      "Accuracy:  0.7052575677110993 \n",
      "F1:  0.6727826639341477 \n",
      "Precision:  0.7924314057319584 \n",
      "Recall:  0.6821951093902918 \n",
      "\n",
      "Model:  Pipeline(steps=[('vect', CountVectorizer()), ('clf', MultinomialNB())]) \n",
      "Accuracy:  0.7728359001593202 \n",
      "F1:  0.745098233005215 \n",
      "Precision:  0.7621626411174734 \n",
      "Recall:  0.7636463041415988 \n",
      "\n",
      "Model:  Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
      "                ('clf', RandomForestClassifier())]) \n",
      "Accuracy:  0.7563728093467871 \n",
      "F1:  0.7433208474689617 \n",
      "Precision:  0.7661960171611233 \n",
      "Recall:  0.7446595960715511 \n",
      "\n",
      "Model:  Pipeline(steps=[('vect', CountVectorizer()),\n",
      "                ('tfidf', TfidfTransformer(use_idf=False)),\n",
      "                ('clf', RandomForestClassifier())]) \n",
      "Accuracy:  0.7594264471587892 \n",
      "F1:  0.744335495017608 \n",
      "Precision:  0.7677905641596567 \n",
      "Recall:  0.7468424242674081 \n",
      "\n",
      "Model:  Pipeline(steps=[('vect', CountVectorizer()), ('clf', RandomForestClassifier())]) \n",
      "Accuracy:  0.7624800849707913 \n",
      "F1:  0.7483494853312898 \n",
      "Precision:  0.7721960288275167 \n",
      "Recall:  0.7501387163846078 \n",
      "\n",
      "Model:  Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
      "                ('clf', SVC())]) \n",
      "Accuracy:  0.8186404673393521 \n",
      "F1:  0.8135540041784731 \n",
      "Precision:  0.8274134771443714 \n",
      "Recall:  0.8102879624833934 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = []\n",
    "f1 = []\n",
    "precision = []\n",
    "recall = []\n",
    "\n",
    "for text_clf in model_list:\n",
    "    \n",
    "    text_clf.fit(twenty_train.data, twenty_train.target)\n",
    "    docs_test = twenty_test.data\n",
    "    predicted = text_clf.predict(docs_test)\n",
    "    \n",
    "    acc = np.mean(predicted == twenty_test.target)\n",
    "    prec = metrics.precision_score(twenty_test.target, predicted, average = 'macro')\n",
    "    rec = metrics.recall_score(twenty_test.target, predicted, average = 'macro')\n",
    "    f = metrics.f1_score(twenty_test.target, predicted, average = 'macro')\n",
    "    \n",
    "    accuracy.append(acc)\n",
    "    f1.append(f)\n",
    "    precision.append(prec)\n",
    "    recall.append(rec)\n",
    "    \n",
    "    print('Model: ', text_clf, \n",
    "          '\\nAccuracy: ', acc, \n",
    "          '\\nF1: ', f,\n",
    "          '\\nPrecision: ', prec,\n",
    "          '\\nRecall: ', rec, '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
